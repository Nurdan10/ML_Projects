{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f34e1d-ccfd-4b77-b14a-31ee7dc90580",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dengesiz Veri Seti\n",
    "Bir iş için sınıflandırma modeli yaratıyorsunuz ve bu modelin doğruluk değeri %95 çıkıyor. Her şey güzel. Modeliniz kullanılmaya başlanıyor ama başarısız olduğu, her zaman aynı sınıfı tahminlediği fark ediliyor. Veri setini tekrar incelediğinizde tespit edilemeyen sınıfın veri setindeki oranın %5 olduğunu görüyorsunuz. Yani modelinizin başarısızlığı dengesiz veri setinden (Imbalanced Dataset) kaynaklı.\n",
    "Dengesiz veri seti sınıflandırma problemlerinde görülür ve sınıf dağılımlarının birbirine yakın olmadığı durumlarda ortaya çıkar. Problem çoğunluğa sahip sınıfın azınlık sınıfını domine etmesinden kaynaklanır. Oluşturulan model çoğunluğa sahip sınıfa yakınlık gösterir, bu da azınlık sınıfının kötü sınıflandırılmasına sebep olur.\n",
    "Dengesiz veri setleriyle karşılaştığımızda doğru gözlem yapabilmek ve dengeyi sağlayabilmek için uygulayabileceğimiz çeşitli yöntemler vardır:\n",
    "Doğru Metrik Seçimi\n",
    "Precision\n",
    "Recall\n",
    "F1-score\n",
    "ROC Curve\n",
    "AUC\n",
    "Resampling\n",
    "Oversampling\n",
    "Random Oversampling\n",
    "SMOTE Oversampling\n",
    "Undersampling\n",
    "Random Undersampling\n",
    "NearMiss Undersampling\n",
    "Undersampling (Tomek links)\n",
    "Undersampling (Cluster Centroids)\n",
    "Daha fazla veri toplamak\n",
    "Sınıflandırma modellerinde bulunan “class_weight” parametresi kullanılarak azınlık ve çoğunluk sınıflarından eşit şekilde öğrenebilen model yaratılması,\n",
    "Tek bir modele değil , diğer modellerdeki performanslara da bakılması,\n",
    "Daha farklı bir yaklaşım uygulanıp Anomaly detection veya Change detection yapmak\n",
    "Dengesizlik içeren Credit Card Fraud Detection veri setini inceleyip, daha sonrasında bu dengesizlikle başa çıkabilmek için veri setine çeşitli yöntemler uygulayacağız.\n",
    "\n",
    "Veri Setinin İncelenmesi\n",
    "Kredi kartı şirketlerinin dolandırıcılığı tespit etmeleri önemlidir, müşterilerine yanlış ücretlendirilme yapılmasını istemezler.\n",
    "Bu veri seti kullanılarak dolandırıcılık yapılmış kredi kartlarını tespit eden bir model oluşturulmak isteniliyor.\n",
    "Veri seti eylül 2013'te avrupada kredi kartıyla yapılan işlemlerden ve bu işlemlerin fraud(dolandırıcılık) ise 1 değilse 0 olarak etiketlenmesiyle oluşmuştur. Gizlilik nedeniyle arka plan bilgisi çok fazla bulunmuyor ve \"Time\",\"Amount\" değişkeni haricinde diğer değişkenler PCA(Principal component analysis) ile dönüştürülmüştür.\n",
    "\"Time\" : ilk işlem ile her işlem arasındaki saniye\n",
    "\"Amount\": maliyet\n",
    "ilk olarak veri setini okutup, boş değer olup olmadığını gözlemleyip, Class değişkenin dağılımına bakacağız. Daha sonrasında \"Amount\" ve \"Time\" değişkenini standartlaştırıyoruz. Veriyi hold out yöntemiyle ayırıp, sınıflandırma modeli olan logistic regression ile modeli oluşturuyoruz. Tek bir model üzerinden gideceğiz.\n",
    "In [1]:\n",
    "# Gerekli kütüphaneler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score,recall_score,roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc,rcParams\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "In [3]:\n",
    "# Veri setinin okutulması\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.head()\n",
    "Out[3]:\n",
    "\n",
    "TimeV1V2V3V4V5V6V7V8V9...V21V22V23V24V25V26V27V28AmountClass00.0-1.359807-0.0727812.5363471.378155-0.3383210.4623880.2395990.0986980.363787...-0.0183070.277838-0.1104740.0669280.128539-0.1891150.133558-0.021053149.62010.01.1918570.2661510.1664800.4481540.060018-0.082361-0.0788030.085102-0.255425...-0.225775-0.6386720.101288-0.3398460.1671700.125895-0.0089830.0147242.69021.0-1.358354-1.3401631.7732090.379780-0.5031981.8004990.7914610.247676-1.514654...0.2479980.7716790.909412-0.689281-0.327642-0.139097-0.055353-0.059752378.66031.0-0.966272-0.1852261.792993-0.863291-0.0103091.2472030.2376090.377436-1.387024...-0.1083000.005274-0.190321-1.1755750.647376-0.2219290.0627230.061458123.50042.0-1.1582330.8777371.5487180.403034-0.4071930.0959210.592941-0.2705330.817739...-0.0094310.798278-0.1374580.141267-0.2060100.5022920.2194220.21515369.990\n",
    "5 rows × 31 columns\n",
    "In [4]:\n",
    "# Veri setindeki değişken ve gözlem sayısı\n",
    "print(\"Gözlem sayısı : \" ,len(df))\n",
    "print(\"Değişken sayısı : \", len(df.columns))\n",
    "\n",
    "Gözlem sayısı :  284807\n",
    "Değişken sayısı :  31\n",
    "In [5]:\n",
    "# veri setindeki değişkenlerin tiplerini ve boş değer içerip içermediğini gözlemlemek istiyoruz\n",
    "df.info()\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 284807 entries, 0 to 284806\n",
    "Data columns (total 31 columns):\n",
    " #   Column  Non-Null Count   Dtype  \n",
    "---  ------  --------------   -----  \n",
    " 0   Time    284807 non-null  float64\n",
    " 1   V1      284807 non-null  float64\n",
    " 2   V2      284807 non-null  float64\n",
    " 3   V3      284807 non-null  float64\n",
    " 4   V4      284807 non-null  float64\n",
    " 5   V5      284807 non-null  float64\n",
    " 6   V6      284807 non-null  float64\n",
    " 7   V7      284807 non-null  float64\n",
    " 8   V8      284807 non-null  float64\n",
    " 9   V9      284807 non-null  float64\n",
    " 10  V10     284807 non-null  float64\n",
    " 11  V11     284807 non-null  float64\n",
    " 12  V12     284807 non-null  float64\n",
    " 13  V13     284807 non-null  float64\n",
    " 14  V14     284807 non-null  float64\n",
    " 15  V15     284807 non-null  float64\n",
    " 16  V16     284807 non-null  float64\n",
    " 17  V17     284807 non-null  float64\n",
    " 18  V18     284807 non-null  float64\n",
    " 19  V19     284807 non-null  float64\n",
    " 20  V20     284807 non-null  float64\n",
    " 21  V21     284807 non-null  float64\n",
    " 22  V22     284807 non-null  float64\n",
    " 23  V23     284807 non-null  float64\n",
    " 24  V24     284807 non-null  float64\n",
    " 25  V25     284807 non-null  float64\n",
    " 26  V26     284807 non-null  float64\n",
    " 27  V27     284807 non-null  float64\n",
    " 28  V28     284807 non-null  float64\n",
    " 29  Amount  284807 non-null  float64\n",
    " 30  Class   284807 non-null  int64  \n",
    "dtypes: float64(30), int64(1)\n",
    "memory usage: 67.4 MB\n",
    "In [6]:\n",
    "# 1 sınıfının veri setinde bulunma oranı %0.2, 0 sınıfının ise %99.8\n",
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "df['Class'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "ax[0].set_title('dağılım')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Class',data=df,ax=ax[1])\n",
    "ax[1].set_title('Class')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "In [7]:\n",
    "# Time ve Amount değişkenlerini standartlaştırma\n",
    "rob_scaler = RobustScaler()\n",
    "df['Amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['Time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "df.head()\n",
    "Out[7]:\n",
    "\n",
    "TimeV1V2V3V4V5V6V7V8V9...V21V22V23V24V25V26V27V28AmountClass0-0.994983-1.359807-0.0727812.5363471.378155-0.3383210.4623880.2395990.0986980.363787...-0.0183070.277838-0.1104740.0669280.128539-0.1891150.133558-0.0210531.78327401-0.9949831.1918570.2661510.1664800.4481540.060018-0.082361-0.0788030.085102-0.255425...-0.225775-0.6386720.101288-0.3398460.1671700.125895-0.0089830.014724-0.26982502-0.994972-1.358354-1.3401631.7732090.379780-0.5031981.8004990.7914610.247676-1.514654...0.2479980.7716790.909412-0.689281-0.327642-0.139097-0.055353-0.0597524.98372103-0.994972-0.966272-0.1852261.792993-0.863291-0.0103091.2472030.2376090.377436-1.387024...-0.1083000.005274-0.190321-1.1755750.647376-0.2219290.0627230.0614581.41829104-0.994960-1.1582330.8777371.5487180.403034-0.4071930.0959210.592941-0.2705330.817739...-0.0094310.798278-0.1374580.141267-0.2060100.5022920.2194220.2151530.6705790\n",
    "5 rows × 31 columns\n",
    "In [8]:\n",
    "# Hold out yöntemi uygulayıp veri setini eğitim ve test olarak ikiye ayırıyoruz.(%80,%20)\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123456)\n",
    "In [9]:\n",
    "# modelin tanımlanıp, eğitilmesi ve başarı skoru\n",
    "model = LogisticRegression(random_state=123456)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f\"%(accuracy))\n",
    "\n",
    "Accuracy: 0.999\n",
    "\n",
    "Accuracy sistemde doğru olarak yapılan tahminlerin tüm tahminlere oranıdır.\n",
    "Oluşturduğumuz modelin doğruluk skoru 0.999. Modelimiz mükemmel çalışıyor diyebiliriz, değil mi?\n",
    "Performansını incelemek için birde Confusion Matrix'ine bakalım.\n",
    "\n",
    "Confusion Matrix\n",
    "Confusion Matrix, bir sınıflandırma modelinin gerçek değerlerinin test verisi üzerindeki performansını açıklamak için kullanılan bir tablodur.\n",
    "Tahmini ve gerçek değerlerin 4 farklı kombinasyonunu içermektedir.\n",
    "\n",
    "True Positives (TP) : Pozitif tahmin edildi ve bu doğru.\n",
    "True Negative (TN) : Negatif tahmin edildi ve bu doğru.\n",
    "False Positive (FP) : Pozitif tahmin edildi ve bu yanlış.\n",
    "False Negative (FN) : Negatif tahmin edildi ve bu yanlış.\n",
    "In [10]:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.rcParams.update({'font.size': 19})\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontdict={'size':'16'})\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45,fontsize=12,color=\"blue\")\n",
    "    plt.yticks(tick_marks, classes,fontsize=12,color=\"blue\")\n",
    "    rc('font', weight='bold')\n",
    "    fmt = '.1f'\n",
    "    thresh = cm.max()\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"red\")\n",
    "\n",
    "    plt.ylabel('True label',fontdict={'size':'16'})\n",
    "    plt.xlabel('Predicted label',fontdict={'size':'16'})\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred=y_pred), classes=['Non Fraud','Fraud'],\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "\n",
    "\n",
    "Non Fraud sınıfı için 56870 (TP) doğru, 5 (FP) yanlış toplam 56875 tahmin yapılmış.\n",
    "Fraud sınıfı için 31 (FN) yanlış, 56 (TN) doğru toplam 87 tahmin yapılmış.\n",
    "Model bize Fraud durumunu 0.99 doğrulukla tahmin edebildiğini söylüyor.Ama confusion Matrix'i incelediğimizde Fraud sınıfındaki yanlış tahminlerin oranı hayli yüksek. Çoğunluk sınıfını tahmin etmekte başarılıyken, azınlık sınıfını tahmin etmede başarılı değildir. Yani model 0.99 oranla non-fraud sınıfını doğru tahmin etmekte.\n",
    "Non Fraud sınıfına ait gözlem sayısının fraud sınıfına ait gözlem sayısından fazla olması, modelin Non Fraud sınıfını tahminlemede başarılı olmasına neden olmakta.\n",
    "Yaptığımız bu gözlem ile accuarcy score'un sınıflandırma modelleri için iyi bir performans ölçümü olmadığını söyleyebiliriz, özelliklede elimizdeki veri setindeki gibi dengesizlik içeriyorsa.\n",
    "Veri setini inceledik, dengesizlikle nasıl başa çıkıp model oluşturabiliceğimize, hangi yöntemlerin uygulanabileceğine ve performansını hangi metriklerle ölçebileceğimize bakabiliriz.\n",
    "\n",
    "Doğru Metrik Seçimi\n",
    "Doğruluk değerinin (Accuracy Score) yeterli olmadığını gördük. Modelin performansını ölçmek için farklı metriklere bakmamız gerekiyor.\n",
    "Precision (Kesinlik): Pozitif olarak tahmin edilenlerin ne kadarının gerçekte pozitif olduğunu gösterir. Eğer precision düşük ise çok sayıda hatalı pozitif olduğunu ifade eder.\n",
    "Recall (Duyarlılık): Pozitif olarak tahmin etmemiz gereken değerlerin ne kadarını pozitif tahmin ettiğimizi gösterir. Eğer recall düşük ise çok sayıda yanlış negatif olduğunu ifade eder. Mümkün olduğu kadar yüksek olmalıdır.\n",
    "F1 score: Düşük precison ve yüksek recall veya tam tersi durumda iki modeli karşılaştırmak güçtür. Karşılaştırılabilir bir hale getirmek F1 score'u precision ve recall'u aynı anda ölçülmesine yardımcı olur. Precision ve Duyarlılık değerlerinin harmonik ortalamasını göstermektedir.\n",
    "Modelimiz için bu metrikleri inceleyelim.\n",
    "Sınıflandırma raporu, ana sınıflandırma ölçütlerinin sınıf bazında temsilini gösterir.\n",
    "In [10]:\n",
    "#sınıflandırma raporu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00     56875\n",
    "           1       0.92      0.64      0.76        87\n",
    "\n",
    "    accuracy                           1.00     56962\n",
    "   macro avg       0.96      0.82      0.88     56962\n",
    "weighted avg       1.00      1.00      1.00     56962\n",
    "\n",
    "\n",
    "Precision ölçüsünü herbir sınıf için inceleyelim.\n",
    "0 (non fraud )sınıfı için yapılan tahminlerden kaçının doğru olduğunu verir. Confusion matrix'ine bakıldığında 56870 + 31 = 56901 tane non fraud sınıfı tahmini yapılmış ve bunun 56870 tanesi doğru tahmin edilmiş. 0 sınıfı için Precision değeri 1'dir (56870 / 56901 )\n",
    "1 (fraud) sınıfı için yapılan tahminlerden kaçının doğru olduğunu verir. Confusion matrix'ine bakıldığında 5 + 56 = 61 tane fraud sınıfı tahmini yapılmış ve bunun 56 tanesi doğru tahmin edilmiş. 0 sınıfı için Precision değeri 0.92'dir (56 / 61)\n",
    "Recall ölçüsünü herbir sınıf için inceleyelim.\n",
    "0(non fraud) sınıfı için tahmin etmemiz gereken değerlerin ne kadarını doğru tahmin ettiğimizi gösterir. 56870 + 5 = 56875 tane non fraud sınıfına ait gözlemimiz var ve bunların 56870 i doğru tahmin edilmiş. 0 sınıfı için recall değeri 56870 / 56875 = 1 'dir.\n",
    "1(fraud) sınıfı için tahmin etmemiz gereken değerlerin ne kadarını doğru tahmin ettiğimizi gösterir. 31 + 56 = 87 tane fraud sınıfına ait gözlemimiz var ve bunların 56'si doğru tahmin edilmiş. 1 sınıfı için recall değeri 56 / 87 = 0.64 'dir.\n",
    "Recall değerinlerine bakıldığında 1 sınıfın tahmin edilme başarısızlığını çok rahat görebiliyoruz.\n",
    "F1-score'u da recall ve precision değerlerinin harmonik ortalamsını ifade ediyor.\n",
    "Support ise sınıfların gerçek değerlerinin sayısını ifade etmekte. Ölçümlerin yapısal zayıflıklarını gösterebilir yani Sınıflar arasındaki gözlem sayısındaki dengesizliğin ölçümleri etkilediğini söyliyebiliriz.\n",
    "\n",
    "ROC curve\n",
    "ROC eğrisi , tüm sınıflandırma eşiklerinde bir sınıflandırma modelinin performansını gösteren bir grafiktir. Bu eğri iki parametreyi çizer:\n",
    "True Positive Rate : Recall\n",
    "\n",
    "False Positive Rate : Fraud'ı tespit etmedeki başarısızlık\n",
    "\n",
    "Farklı sınıflandırma eşiklerinde gerçek pozitif oran ve yanlış pozitif oran eğrisidir. (0,0) ‘da başlar ve (1,1)’ de biter. İyi bir model, 0'dan 1'e hızla giden bir eğri üretir.\n",
    "\n",
    "AUC (Area under the ROC curve)\n",
    "ROC eğrisini tek bir sayı ile özetler. (0,0) 'dan (1,1)' e kadar tüm ROC eğrisinin altındaki iki boyutlu alanın tamamını ölçer. En iyi değer 1, en kötü değeri 0.5'dir.\n",
    "In [11]:\n",
    "# Auc Roc Curve\n",
    "def generate_auc_roc_curve(clf, X_test):\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "generate_auc_roc_curve(model, X_test)\n",
    "\n",
    "\n",
    "In [12]:\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC ROC Curve with Area Under the curve = %.3f\"%auc)\n",
    "\n",
    "AUC ROC Curve with Area Under the curve = 0.961\n",
    "\n",
    "Not : ROC eğrisinin (AUC) altındaki alan, genel sınıflandırma performansını değerlendirir. AUC, bir sınıfa diğerine daha fazla önem vermediğinden, azınlık sınıfını iyi yansıtmamaktadır.\n",
    "Dengesizliği gidermek için çeşitli yöntemleri veri setine uygulayalım.\n",
    "NOT: Yöntemler eğitim setine uygulanmalıdır. Test setine uygulanırsa doğru değerlendirme yapılamaz.\n",
    "\n",
    "Resampling\n",
    "Yeniden örnekleme(Resampling), azınlık sınıfına yeni örnekler ekleyerek veya çoğunluk sınıfından örnekler çıkarılarak veri setinin daha dengeli hale getirilmesidir.\n",
    "Oversampling\n",
    "Azınlık sınıfına ait örneklerin kopyalanmasıyla veri setini dengeler.\n",
    "Random Oversampling:\n",
    "Azınlık sınıfından rastgele seçilen örneklerin eklenmesiyle veri setinin dengelenmesidir.\n",
    "Veri setiniz küçükse bu teknik kullanılabilinir.\n",
    "Overfitting’e neden olabilir.\n",
    "RandomOverSampler metodu sampling_strategy argümanını almakta, sampling_stratefy='minority' dendiğinde azınlık sınıfının sayısını çoğunluk sınıfının sayısa eşitleyecek şekilde artırır.\n",
    "Bu argümana float bir değerde girebiliriz. Örneğin azınlık sınıfımızın sayısı 1000, çoğunluk sınıfının sayısı 100 olsun. sampling_stratefy = 0.5 dersek, azınlık sınıfının sayısı 500 olucak şekilde ekleme yapılacaktır.\n",
    "In [13]:\n",
    "# random oversampling önce eğitim setindeki sınıf sayısı\n",
    "y_train.value_counts()\n",
    "Out[13]:\n",
    "0    227440\n",
    "1       405\n",
    "Name: Class, dtype: int64\n",
    "In [14]:\n",
    "# RandomOver Sampling uygulanması (Eğitim setine uygulanıyor)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_randomover, y_randomover = oversample.fit_resample(X_train, y_train)\n",
    "In [15]:\n",
    "# random oversampling den sonra eğitim setinin sınıf sayısı\n",
    "y_randomover.value_counts()\n",
    "Out[15]:\n",
    "1    227440\n",
    "0    227440\n",
    "Name: Class, dtype: int64\n",
    "In [16]:\n",
    "# modelin eğitilmesi ve başarı oranı\n",
    "model.fit(X_randomover, y_randomover)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f%%\" % (accuracy))\n",
    "\n",
    "Accuracy: 0.977%\n",
    "In [17]:\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred=y_pred), classes=['Non Fraud','Fraud'],\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "\n",
    "In [18]:\n",
    "#sınıflandırma raporu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.98      0.99     56875\n",
    "           1       0.05      0.86      0.10        87\n",
    "\n",
    "    accuracy                           0.98     56962\n",
    "   macro avg       0.53      0.92      0.55     56962\n",
    "weighted avg       1.00      0.98      0.99     56962\n",
    "\n",
    "\n",
    "Random Oversampling uygulandıktan sonra eğitilen modelin doğruluk değeri 0.97'dır, düşüş gözlenmekte. Confusion Matrix ve Sınıflandırma raporuna bakıldığında, tahmin edilen fraud sınıflarının yanlış çıkma oranı yüksek görünüyor, bu da 1 sınıfın precision değerini düşürmüş durumda. Ama 1 sınıfının recall değerinde de bir yükseliş var, modelin fraud sınıfını doğru tahmin etme oranı artmıştır. İlk modele göre Non fraud sınıfının tahmin edilme başarısı düşmüş durumda ama fraud sınıfının doğru tahmin edilmesindeki yükselme randomoversampling yapıldıktan sonra oluşturulmuş modeli tercih etmemizde büyük bir etken.\n",
    "\n",
    "SMOTE Oversampling:\n",
    "Overfitting’i önlemek için azınlık sınıfından sentetik örnekler oluşturulması.\n",
    "Önce azınlık sınıfından rastgele bir örnek seçilir.\n",
    "Daha sonra bu örnek için en yakın komşulardan k tanesi bulunur.\n",
    "k en yakın komşulardan biri rastgele seçilir ve azınlık sınıfından rastgele seçilen örnekle birleştirilip özellik uzayında bir çizgi parçası oluşturarak sentetik örnek oluşturulur.\n",
    "In [19]:\n",
    "# smote dan önce eğitim setindeki sınıf sayısı\n",
    "y_train.value_counts()\n",
    "Out[19]:\n",
    "0    227440\n",
    "1       405\n",
    "Name: Class, dtype: int64\n",
    "In [20]:\n",
    "# Smote uygulanması (Eğitim setine uygulanıyor)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)\n",
    "In [21]:\n",
    "# smote dan sonra eğitim setinin sınıf sayısı\n",
    "y_smote.value_counts()\n",
    "Out[21]:\n",
    "1    227440\n",
    "0    227440\n",
    "Name: Class, dtype: int64\n",
    "In [22]:\n",
    "# modelin eğitilmesi ve başarı oranı\n",
    "model.fit(X_smote, y_smote)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f%%\" % (accuracy))\n",
    "\n",
    "Accuracy: 0.975%\n",
    "In [23]:\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred=y_pred), classes=['Non Fraud','Fraud'],\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "\n",
    "In [24]:\n",
    "#sınıflandırma raporu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.98      0.99     56875\n",
    "           1       0.05      0.86      0.10        87\n",
    "\n",
    "    accuracy                           0.98     56962\n",
    "   macro avg       0.53      0.92      0.54     56962\n",
    "weighted avg       1.00      0.98      0.99     56962\n",
    "\n",
    "\n",
    "Undersampling\n",
    "Çoğunluk sınıfına ait örneklerin çıkarılmasıyla veri setini dengeleme tekniğidir. Büyük veri setine sahip olunduğunda kullanılabilir. Elimizdeki veri seti büyük olmadığı için verimli sonuçlar alınmayacaktır. Ama yöntemleri açıklayıp bazılarının nasıl uygulanabiliceğini göstereceğim.\n",
    "Random Undersampling:\n",
    "Çıkarılan örnekler rastgele seçilir.\n",
    "Büyük veri setine sahipseniz bu tekniği kullanabilirsiniz.\n",
    "Rastgele seçimden dolayı bilgi kaybı yaşanabilir.\n",
    "In [25]:\n",
    "# random undersampling den önce eğitim setindeki sınıf sayısı\n",
    "y_train.value_counts()\n",
    "Out[25]:\n",
    "0    227440\n",
    "1       405\n",
    "Name: Class, dtype: int64\n",
    "In [26]:\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# transform the dataset\n",
    "ranUnSample = RandomUnderSampler()\n",
    "X_ranUnSample, y_ranUnSample = ranUnSample.fit_resample(X_train, y_train)\n",
    "In [27]:\n",
    "# Random undersampling sonra\n",
    "y_ranUnSample.value_counts()\n",
    "Out[27]:\n",
    "1    405\n",
    "0    405\n",
    "Name: Class, dtype: int64\n",
    "\n",
    "NearMiss Undersampling:\n",
    "Bilgi kaybını önler.\n",
    "KNN algoritmasına dayanır.\n",
    "Çoğunluk sınıfına ait örneklerin azınlık sınıfına ait örneklerle olan uzaklığı hesaplanır.\n",
    "Belirtilen k değerine göre uzaklığı kısa olan örnekler korunur.\n",
    "Undersampling (Tomek links):\n",
    "Farklı sınıflara ait en yakın iki örneğin arasındaki çoğunluk sınıfının örnekleri kaldırılarak, iki sınıf arasındaki boşluk arttırılır.\n",
    "Undersampling (Cluster Centroids):\n",
    "Önemsiz örneklerin veri setinden çıkarılmasıdır.Örneğin önemli veya önemsiz olduğu kümelemeyle belirlenir.\n",
    "Undersampling ve Oversampling tekniklerinin bir araya gelmesiyle daha dengeli veri setleri oluşturulabilinir.\n",
    "Diğer Yöntemler\n",
    "\n",
    "Daha fazla veri toplamak,\n",
    "Sınıflandırma modellerinde bulunan “class_weight” parametresi kullanılarak azınlık ve çoğunluk sınıflarından eşit şekilde öğrenebilen model yaratılması,\n",
    "Tek bir modele değil , diğer modellerdeki performanslara da bakılması,\n",
    "Daha farklı bir yaklaşım uygulanıp Anomaly detection veya Change detection yapmak\n",
    "gibi yöntemlerle de dengesiz veri setiyle başa çıkılır.\n",
    "Hangi yöntemin en iyi sonuç vereceği elimizdeki veri setine bağlıdır. Yöntemler denenerek veri setine en uygun olanın seçilmesi en iyi sonucu sağlar diyebiliriz.\n",
    "\n",
    "REFERANS\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62\n",
    "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
